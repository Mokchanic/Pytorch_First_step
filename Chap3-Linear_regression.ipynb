{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chap3 - Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "X = torch.Tensor(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor([[1,2,3], [4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기울기를 계산하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(data = [2.0, 3.0], requires_grad = True)\n",
    "y = x**2\n",
    "z = 2*y + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([3.0, 4.0])\n",
    "loss = torch.sum(torch.abs(z-target))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8., 12.]) None None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6c1d48845c75>:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  print(x.grad, y.grad, z.grad)\n"
     ]
    }
   ],
   "source": [
    "print(x.grad, y.grad, z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형회귀 분석모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #torch 라이브러리 불러옴\n",
    "import torch.nn as nn # torch의 신경망 모델들을 불러옴\n",
    "import torch.optim as optim # torch의 경사하강법 알고리즘을 불러옴\n",
    "import torch.nn.init as init # 텐서에 초기값을 주기 위해 필요한 함수들이 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 1000\n",
    "num_epoch = 500\n",
    "\n",
    "x = init.uniform_(torch.Tensor(num_data, 1),-10,10)\n",
    "noise = init.normal_(torch.FloatTensor(num_data, 1), std=1)\n",
    "y = 2 * x + 3\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1,1)\n",
    "loss_func = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.1431)\n",
      "-0.3401641845703125 0.37364789843559265\n",
      "tensor(9.6793)\n",
      "0.15580324828624725 0.38508787751197815\n",
      "tensor(7.2702)\n",
      "0.6455875635147095 0.40034788846969604\n",
      "tensor(5.0098)\n",
      "1.1186367273330688 0.4227278530597687\n",
      "tensor(3.1898)\n",
      "1.5345605611801147 0.4611278474330902\n",
      "tensor(2.5226)\n",
      "1.7587873935699463 0.5308078527450562\n",
      "tensor(2.3744)\n",
      "1.833625078201294 0.6199279427528381\n",
      "tensor(2.2689)\n",
      "1.8749167919158936 0.7133678793907166\n",
      "tensor(2.1697)\n",
      "1.9062597751617432 0.8076677322387695\n",
      "tensor(2.0756)\n",
      "1.9252406358718872 0.9025877118110657\n",
      "tensor(1.9841)\n",
      "1.9398618936538696 0.9970276355743408\n",
      "tensor(1.8956)\n",
      "1.9486486911773682 1.0905076265335083\n",
      "tensor(1.8111)\n",
      "1.9545221328735352 1.182127594947815\n",
      "tensor(1.7285)\n",
      "1.963297963142395 1.2724676132202148\n",
      "tensor(1.6494)\n",
      "1.970413088798523 1.3609676361083984\n",
      "tensor(1.5730)\n",
      "1.976675271987915 1.4480277299880981\n",
      "tensor(1.5008)\n",
      "1.9786310195922852 1.532767653465271\n",
      "tensor(1.4331)\n",
      "1.9795531034469604 1.6147676706314087\n",
      "tensor(1.3698)\n",
      "1.980455756187439 1.6941677331924438\n",
      "tensor(1.3097)\n",
      "1.9840664863586426 1.771448016166687\n",
      "tensor(1.2535)\n",
      "1.9874916076660156 1.8459879159927368\n",
      "tensor(1.2024)\n",
      "1.9905999898910522 1.9171879291534424\n",
      "tensor(1.1558)\n",
      "1.9908450841903687 1.9852080345153809\n",
      "tensor(1.1132)\n",
      "1.9922940731048584 2.0502679347991943\n",
      "tensor(1.0740)\n",
      "1.9909600019454956 2.112567663192749\n",
      "tensor(1.0391)\n",
      "1.9898669719696045 2.171407461166382\n",
      "tensor(1.0073)\n",
      "1.9930446147918701 2.2273876667022705\n",
      "tensor(0.9787)\n",
      "1.9928463697433472 2.2805874347686768\n",
      "tensor(0.9535)\n",
      "1.9898127317428589 2.330467462539673\n",
      "tensor(0.9313)\n",
      "1.9885972738265991 2.377307415008545\n",
      "tensor(0.9118)\n",
      "1.987890601158142 2.42126727104187\n",
      "tensor(0.8945)\n",
      "1.9854005575180054 2.462587356567383\n",
      "tensor(0.8792)\n",
      "1.9863357543945312 2.50150728225708\n",
      "tensor(0.8657)\n",
      "1.9875143766403198 2.537987470626831\n",
      "tensor(0.8535)\n",
      "1.9887800216674805 2.572707414627075\n",
      "tensor(0.8434)\n",
      "1.9890114068984985 2.60414719581604\n",
      "tensor(0.8348)\n",
      "1.987437129020691 2.6333072185516357\n",
      "tensor(0.8274)\n",
      "1.9863338470458984 2.6601474285125732\n",
      "tensor(0.8213)\n",
      "1.987081527709961 2.6846673488616943\n",
      "tensor(0.8158)\n",
      "1.9883044958114624 2.7079873085021973\n",
      "tensor(0.8108)\n",
      "1.9899805784225464 2.7300872802734375\n",
      "tensor(0.8064)\n",
      "1.992482304573059 2.7508273124694824\n",
      "tensor(0.8024)\n",
      "1.9944969415664673 2.7706480026245117\n",
      "tensor(0.7990)\n",
      "1.9953625202178955 2.7889881134033203\n",
      "tensor(0.7962)\n",
      "1.9944199323654175 2.8055286407470703\n",
      "tensor(0.7938)\n",
      "1.9951189756393433 2.8207077980041504\n",
      "tensor(0.7917)\n",
      "1.9950016736984253 2.8352274894714355\n",
      "tensor(0.7899)\n",
      "1.9968475103378296 2.8483076095581055\n",
      "tensor(0.7883)\n",
      "1.9983834028244019 2.860827922821045\n",
      "tensor(0.7870)\n",
      "1.9994014501571655 2.8722283840179443\n"
     ]
    }
   ],
   "source": [
    "label = y_noise\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    \n",
    "    loss = loss_func(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i%10 == 0:\n",
    "        print(loss.data)\n",
    "        param_list = list(model.parameters())\n",
    "        print(param_list[0].item(), param_list[1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
